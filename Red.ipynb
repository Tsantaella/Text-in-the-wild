{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import h5py\n",
    "\n",
    "import scipy.io\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathImgs = [\"D:/Datasets/CharALL/English/Img/GoodImg/Bmp/\",\n",
    "            \"D:/Datasets/CharALL/English/Fnt/\",\n",
    "            \"D:/Datasets/CharALL/English/Hnd/Img/\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargado de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "total_labels = np.arange(0,62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dirs = [x+'/' for x in os.listdir(pathImgs[0])]\n",
    "label_cont = 0\n",
    "\n",
    "for d in img_dirs:\n",
    "    imgs = os.listdir(pathImgs[0]+d)\n",
    "    for img in imgs:\n",
    "        data.append(cv2.imread(pathImgs[0]+d+img))\n",
    "        labels.append(total_labels[label_cont])\n",
    "    label_cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dirs = [x+'/' for x in os.listdir(pathImgs[1])]\n",
    "label_cont = 0\n",
    "\n",
    "for d in img_dirs:\n",
    "    imgs = os.listdir(pathImgs[1]+d)\n",
    "    for img in imgs:\n",
    "        data.append(cv2.imread(pathImgs[1]+d+img))\n",
    "        labels.append(total_labels[label_cont])\n",
    "    label_cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dirs = [x+'/' for x in os.listdir(pathImgs[2])]\n",
    "label_cont = 0\n",
    "\n",
    "for d in img_dirs:\n",
    "    imgs = os.listdir(pathImgs[2]+d)\n",
    "    for img in imgs:\n",
    "        data.append(cv2.imread(pathImgs[2]+d+img))\n",
    "        labels.append(total_labels[label_cont])\n",
    "    label_cont += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesado de los datos\n",
    "Hay que reescalar las imagenes porque tienen dimensiones diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [cv2.resize(im, (64,64)) for im in data]\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[60000])\n",
    "plt.show()\n",
    "print(labels[60000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train y test con sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(59285, 64, 64, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(x_train[5])\n",
    "plt.show()\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(128, 3, 3, input_shape=(64,64,3), activation='relu'),\n",
    "    keras.layers.Conv2D(256, 2, 1, activation='relu'),\n",
    "    keras.layers.Conv2D(512, 2, 1, activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1024, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(512, activation='relu'), \n",
    "    keras.layers.Dropout(0.5), \n",
    "    keras.layers.Dense(62),\n",
    "    keras.layers.Activation('softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1853/1853 [==============================] - 760s 410ms/step - loss: 5.2485 - accuracy: 0.4587\n",
      "Epoch 2/20\n",
      "1853/1853 [==============================] - 716s 387ms/step - loss: 0.8736 - accuracy: 0.7430\n",
      "Epoch 3/20\n",
      "1853/1853 [==============================] - 744s 401ms/step - loss: 0.7081 - accuracy: 0.7777\n",
      "Epoch 4/20\n",
      "1853/1853 [==============================] - 719s 388ms/step - loss: 0.6273 - accuracy: 0.7991\n",
      "Epoch 5/20\n",
      "1853/1853 [==============================] - 684s 369ms/step - loss: 0.5515 - accuracy: 0.8202\n",
      "Epoch 6/20\n",
      "1853/1853 [==============================] - 684s 369ms/step - loss: 0.5033 - accuracy: 0.8330\n",
      "Epoch 7/20\n",
      "1853/1853 [==============================] - 710s 383ms/step - loss: 0.4705 - accuracy: 0.8426\n",
      "Epoch 8/20\n",
      "1853/1853 [==============================] - 707s 381ms/step - loss: 0.4306 - accuracy: 0.8525\n",
      "Epoch 9/20\n",
      "1853/1853 [==============================] - 751s 406ms/step - loss: 0.4171 - accuracy: 0.8563\n",
      "Epoch 10/20\n",
      "1853/1853 [==============================] - 722s 390ms/step - loss: 0.4082 - accuracy: 0.8612\n",
      "Epoch 11/20\n",
      "1853/1853 [==============================] - 719s 388ms/step - loss: 0.3729 - accuracy: 0.8687\n",
      "Epoch 12/20\n",
      "1853/1853 [==============================] - 735s 397ms/step - loss: 0.3735 - accuracy: 0.8690\n",
      "Epoch 13/20\n",
      "1853/1853 [==============================] - 720s 389ms/step - loss: 0.3648 - accuracy: 0.8748\n",
      "Epoch 14/20\n",
      "1853/1853 [==============================] - 744s 401ms/step - loss: 0.3505 - accuracy: 0.8770\n",
      "Epoch 15/20\n",
      "1853/1853 [==============================] - 739s 399ms/step - loss: 0.3364 - accuracy: 0.8832\n",
      "Epoch 16/20\n",
      "1853/1853 [==============================] - 730s 394ms/step - loss: 0.3363 - accuracy: 0.8826\n",
      "Epoch 17/20\n",
      "1853/1853 [==============================] - 738s 398ms/step - loss: 0.3170 - accuracy: 0.8894\n",
      "Epoch 18/20\n",
      "1853/1853 [==============================] - 717s 387ms/step - loss: 0.3142 - accuracy: 0.8894\n",
      "Epoch 19/20\n",
      "1853/1853 [==============================] - 745s 402ms/step - loss: 0.3279 - accuracy: 0.8871\n",
      "Epoch 20/20\n",
      "1853/1853 [==============================] - 742s 400ms/step - loss: 0.3106 - accuracy: 0.8921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2193a359e48>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464/464 - 36s - loss: 0.3864 - accuracy: 0.8703\n",
      "\n",
      "Test accuracy: 0.8702604174613953\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 21, 21, 128)       3584      \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 20, 20, 256)       131328    \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 19, 19, 512)       524800    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 41472)             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1024)              42468352  \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 62)                31806     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 62)                0         \n",
      "=================================================================\n",
      "Total params: 43,684,670\n",
      "Trainable params: 43,684,670\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: textRecognitionModel_V2\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"textRecognitionModel_V2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
